{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-24T21:32:35.251006Z",
     "start_time": "2024-11-24T21:32:33.279108Z"
    }
   },
   "source": [
    "from transformers import AutoModel\n",
    "from transformers import AutoTokenizer"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T21:32:37.551211Z",
     "start_time": "2024-11-24T21:32:35.251558Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# load model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('deepvk/USER-bge-m3', trust_remote_code=True)\n",
    "model = AutoModel.from_pretrained('deepvk/USER-bge-m3', trust_remote_code=True)"
   ],
   "id": "b92ef4825c670577",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T21:32:37.567373Z",
     "start_time": "2024-11-24T21:32:37.551717Z"
    }
   },
   "cell_type": "code",
   "source": "import torch",
   "id": "e171574e979fa219",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T21:32:37.598699Z",
     "start_time": "2024-11-24T21:32:37.567975Z"
    }
   },
   "cell_type": "code",
   "source": "torch.cuda.is_available()",
   "id": "155c6447defd21cf",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T21:32:37.614744Z",
     "start_time": "2024-11-24T21:32:37.599701Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# tokenizer = AutoTokenizer.from_pretrained('jinaai/jina-embeddings-v2-base-en', trust_remote_code=True)\n",
    "# model = AutoModel.from_pretrained('jinaai/jina-embeddings-v2-base-en', trust_remote_code=True)"
   ],
   "id": "a1164e6cc7406e7",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T21:51:28.339288Z",
     "start_time": "2024-11-24T21:51:28.329041Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def chunk_by_sentences(input_text: str, tokenizer: callable):\n",
    "    \"\"\"\n",
    "    Split the input text into sentences using the tokenizer\n",
    "    :param input_text: The text snippet to split into sentences\n",
    "    :param tokenizer: The tokenizer to use\n",
    "    :return: A tuple containing the list of text chunks and their corresponding token spans\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(input_text, return_tensors='pt', return_offsets_mapping=True)\n",
    "    punctuation_mark_id = tokenizer.convert_tokens_to_ids('.')\n",
    "    sep_id = tokenizer.convert_tokens_to_ids('[SEP]')\n",
    "    token_offsets = inputs['offset_mapping'][0]\n",
    "    token_ids = inputs['input_ids'][0]\n",
    "    chunk_positions = [\n",
    "        (i, int(start + 1))\n",
    "        for i, (token_id, (start, end)) in enumerate(zip(token_ids, token_offsets))\n",
    "        if token_id == punctuation_mark_id\n",
    "    ]\n",
    "    chunks = [\n",
    "        input_text[x[1] : y[1]]\n",
    "        for x, y in zip([(1, 0)] + chunk_positions[:-1], chunk_positions)\n",
    "    ]\n",
    "    span_annotations = [\n",
    "        (x[0], y[0]) for (x, y) in zip([(1, 0)] + chunk_positions[:-1], chunk_positions)\n",
    "    ]\n",
    "    return chunks, span_annotations"
   ],
   "id": "31d6ce92f52f4799",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T21:51:31.096639Z",
     "start_time": "2024-11-24T21:51:31.084005Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests\n",
    "\n",
    "def chunk_by_tokenizer_api(input_text: str, tokenizer: callable):\n",
    "    # Define the API endpoint and payload\n",
    "    url = 'https://tokenize.jina.ai/'\n",
    "    payload = {\n",
    "        \"content\": input_text,\n",
    "        \"return_chunks\": \"true\",\n",
    "        \"max_chunk_length\": \"512\"\n",
    "    }\n",
    "\n",
    "    # Make the API request\n",
    "    response = requests.post(url, json=payload)\n",
    "    response_data = response.json()\n",
    "\n",
    "    # Extract chunks and positions from the response\n",
    "    chunks = response_data.get(\"chunks\", [])\n",
    "    chunk_positions = response_data.get(\"chunk_positions\", [])\n",
    "\n",
    "    # Adjust chunk positions to match the input format\n",
    "    span_annotations = [(start, end) for start, end in chunk_positions]\n",
    "\n",
    "    return chunks, span_annotations"
   ],
   "id": "ca9de63696bf48f9",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T21:51:38.110338Z",
     "start_time": "2024-11-24T21:51:38.093060Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_text = \"Berlin is the capital and largest city of Germany, both by area and by population. Its more than 3.85 million inhabitants make it the European Union's most populous city, as measured by population within city limits. The city is also one of the states of Germany, and is the third smallest state in the country in terms of area.\"\n",
    "\n",
    "# determine chunks\n",
    "chunks, span_annotations = chunk_by_sentences(input_text, tokenizer)\n",
    "print('Chunks:\\n- \"' + '\"\\n- \"'.join(chunks) + '\"')"
   ],
   "id": "cc36db1daef529a0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunks:\n",
      "- \"Berlin is the capital and largest city of Germany, both by area and by population.\"\n",
      "- \" Its more than 3.85 million inhabitants make it the European Union's most populous city, as measured by population within city limits.\"\n",
      "- \" The city is also one of the states of Germany, and is the third smallest state in the country in terms of area.\"\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T21:51:41.332309Z",
     "start_time": "2024-11-24T21:51:41.323978Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def late_chunking(\n",
    "    model_output: 'BatchEncoding', span_annotation: list, max_length=None\n",
    "):\n",
    "    token_embeddings = model_output[0]\n",
    "    outputs = []\n",
    "    for embeddings, annotations in zip(token_embeddings, span_annotation):\n",
    "        if (\n",
    "            max_length is not None\n",
    "        ):  # remove annotations which go bejond the max-length of the model\n",
    "            annotations = [\n",
    "                (start, min(end, max_length - 1))\n",
    "                for (start, end) in annotations\n",
    "                if start < (max_length - 1)\n",
    "            ]\n",
    "        pooled_embeddings = [\n",
    "            embeddings[start:end].sum(dim=0) / (end - start)\n",
    "            for start, end in annotations\n",
    "            if (end - start) >= 1\n",
    "        ]\n",
    "        pooled_embeddings = [\n",
    "            embedding.detach().cpu().numpy() for embedding in pooled_embeddings\n",
    "        ]\n",
    "        outputs.append(pooled_embeddings)\n",
    "\n",
    "    return outputs"
   ],
   "id": "520850938256db57",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T21:53:23.940455Z",
     "start_time": "2024-11-24T21:53:23.924374Z"
    }
   },
   "cell_type": "code",
   "source": "chunks",
   "id": "210ec66218499806",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Berlin is the capital and largest city of Germany, both by area and by population.',\n",
       " \" Its more than 3.85 million inhabitants make it the European Union's most populous city, as measured by population within city limits.\",\n",
       " ' The city is also one of the states of Germany, and is the third smallest state in the country in terms of area.']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T21:53:11.641479Z",
     "start_time": "2024-11-24T21:53:11.599934Z"
    }
   },
   "cell_type": "code",
   "source": [
    "embeddings_traditional_chunking = model.encoder(torch.tensor(chunks))\n",
    "\n",
    "# chunk afterwards (context-sensitive chunked pooling)\n",
    "inputs = tokenizer(input_text, return_tensors='pt')\n",
    "model_output = model(**inputs)\n",
    "embeddings = late_chunking(model_output, [span_annotations])[0]"
   ],
   "id": "4bfcc52e7453775f",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many dimensions 'str'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[43], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m embeddings_traditional_chunking \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mencoder(\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mchunks\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m# chunk afterwards (context-sensitive chunked pooling)\u001B[39;00m\n\u001B[0;32m      4\u001B[0m inputs \u001B[38;5;241m=\u001B[39m tokenizer(input_text, return_tensors\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpt\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[1;31mValueError\u001B[0m: too many dimensions 'str'"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T21:51:44.563791Z",
     "start_time": "2024-11-24T21:51:44.550264Z"
    }
   },
   "cell_type": "code",
   "source": "dir(model)",
   "id": "74da42b4c2f45955",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T_destination',\n",
       " '__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_apply',\n",
       " '_assisted_decoding',\n",
       " '_auto_class',\n",
       " '_autoset_attn_implementation',\n",
       " '_backward_compatibility_gradient_checkpointing',\n",
       " '_backward_hooks',\n",
       " '_backward_pre_hooks',\n",
       " '_beam_search',\n",
       " '_buffers',\n",
       " '_call_impl',\n",
       " '_check_and_enable_flash_attn_2',\n",
       " '_check_and_enable_sdpa',\n",
       " '_compiled_call_impl',\n",
       " '_constrained_beam_search',\n",
       " '_contrastive_search',\n",
       " '_convert_head_mask_to_5d',\n",
       " '_copy_lm_head_original_to_resized',\n",
       " '_create_repo',\n",
       " '_dispatch_accelerate_model',\n",
       " '_dola_decoding',\n",
       " '_expand_inputs_for_generation',\n",
       " '_extract_past_from_model_output',\n",
       " '_forward_hooks',\n",
       " '_forward_hooks_always_called',\n",
       " '_forward_hooks_with_kwargs',\n",
       " '_forward_pre_hooks',\n",
       " '_forward_pre_hooks_with_kwargs',\n",
       " '_from_config',\n",
       " '_get_backward_hooks',\n",
       " '_get_backward_pre_hooks',\n",
       " '_get_cache',\n",
       " '_get_candidate_generator',\n",
       " '_get_files_timestamps',\n",
       " '_get_initial_cache_position',\n",
       " '_get_logits_processor',\n",
       " '_get_name',\n",
       " '_get_no_split_modules',\n",
       " '_get_resized_embeddings',\n",
       " '_get_resized_lm_head',\n",
       " '_get_stopping_criteria',\n",
       " '_group_beam_search',\n",
       " '_has_unfinished_sequences',\n",
       " '_hf_peft_config_loaded',\n",
       " '_hook_rss_memory_post_forward',\n",
       " '_hook_rss_memory_pre_forward',\n",
       " '_init_added_embeddings_weights_with_mean',\n",
       " '_init_added_lm_head_bias_with_mean',\n",
       " '_init_added_lm_head_weights_with_mean',\n",
       " '_init_weights',\n",
       " '_initialize_weights',\n",
       " '_is_full_backward_hook',\n",
       " '_is_hf_initialized',\n",
       " '_is_quantized_training_enabled',\n",
       " '_is_stateful',\n",
       " '_keep_in_fp32_modules',\n",
       " '_keep_in_fp32_modules',\n",
       " '_keys_to_ignore_on_load_missing',\n",
       " '_keys_to_ignore_on_load_unexpected',\n",
       " '_keys_to_ignore_on_save',\n",
       " '_load_from_state_dict',\n",
       " '_load_pretrained_model',\n",
       " '_load_pretrained_model_low_mem',\n",
       " '_load_state_dict_post_hooks',\n",
       " '_load_state_dict_pre_hooks',\n",
       " '_maybe_initialize_input_ids_for_generation',\n",
       " '_maybe_warn_non_full_backward_hook',\n",
       " '_merge_criteria_processor_list',\n",
       " '_modules',\n",
       " '_named_members',\n",
       " '_no_split_modules',\n",
       " '_non_persistent_buffers_set',\n",
       " '_parameters',\n",
       " '_prepare_attention_mask_for_generation',\n",
       " '_prepare_cache_for_generation',\n",
       " '_prepare_decoder_input_ids_for_generation',\n",
       " '_prepare_encoder_decoder_kwargs_for_generation',\n",
       " '_prepare_generated_length',\n",
       " '_prepare_generation_config',\n",
       " '_prepare_model_inputs',\n",
       " '_prepare_special_tokens',\n",
       " '_prune_heads',\n",
       " '_register_load_state_dict_pre_hook',\n",
       " '_register_state_dict_hook',\n",
       " '_reorder_cache',\n",
       " '_replicate_for_data_parallel',\n",
       " '_resize_token_embeddings',\n",
       " '_sample',\n",
       " '_save_to_state_dict',\n",
       " '_set_default_torch_dtype',\n",
       " '_set_gradient_checkpointing',\n",
       " '_skip_keys_device_placement',\n",
       " '_slow_forward',\n",
       " '_state_dict_hooks',\n",
       " '_state_dict_pre_hooks',\n",
       " '_supports_cache_class',\n",
       " '_supports_default_dynamic_cache',\n",
       " '_supports_flash_attn_2',\n",
       " '_supports_num_logits_to_keep',\n",
       " '_supports_quantized_cache',\n",
       " '_supports_sdpa',\n",
       " '_supports_static_cache',\n",
       " '_temporary_reorder_cache',\n",
       " '_tie_encoder_decoder_weights',\n",
       " '_tie_or_clone_weights',\n",
       " '_tied_weights_keys',\n",
       " '_update_model_kwargs_for_generation',\n",
       " '_upload_modified_files',\n",
       " '_validate_assistant',\n",
       " '_validate_generated_length',\n",
       " '_validate_model_class',\n",
       " '_validate_model_kwargs',\n",
       " '_version',\n",
       " '_wrapped_call_impl',\n",
       " 'active_adapter',\n",
       " 'active_adapters',\n",
       " 'add_adapter',\n",
       " 'add_memory_hooks',\n",
       " 'add_model_tags',\n",
       " 'add_module',\n",
       " 'apply',\n",
       " 'attn_implementation',\n",
       " 'base_model',\n",
       " 'base_model_prefix',\n",
       " 'bfloat16',\n",
       " 'buffers',\n",
       " 'call_super_init',\n",
       " 'can_generate',\n",
       " 'children',\n",
       " 'compile',\n",
       " 'compute_transition_scores',\n",
       " 'config',\n",
       " 'config_class',\n",
       " 'cpu',\n",
       " 'create_extended_attention_mask_for_decoder',\n",
       " 'cuda',\n",
       " 'dequantize',\n",
       " 'device',\n",
       " 'disable_adapters',\n",
       " 'disable_input_require_grads',\n",
       " 'double',\n",
       " 'dtype',\n",
       " 'dummy_inputs',\n",
       " 'dump_patches',\n",
       " 'embeddings',\n",
       " 'enable_adapters',\n",
       " 'enable_input_require_grads',\n",
       " 'encoder',\n",
       " 'estimate_tokens',\n",
       " 'eval',\n",
       " 'extra_repr',\n",
       " 'float',\n",
       " 'floating_point_ops',\n",
       " 'forward',\n",
       " 'framework',\n",
       " 'from_pretrained',\n",
       " 'generate',\n",
       " 'generation_config',\n",
       " 'get_adapter_state_dict',\n",
       " 'get_buffer',\n",
       " 'get_extended_attention_mask',\n",
       " 'get_extra_state',\n",
       " 'get_head_mask',\n",
       " 'get_input_embeddings',\n",
       " 'get_memory_footprint',\n",
       " 'get_output_embeddings',\n",
       " 'get_parameter',\n",
       " 'get_position_embeddings',\n",
       " 'get_submodule',\n",
       " 'gradient_checkpointing_disable',\n",
       " 'gradient_checkpointing_enable',\n",
       " 'half',\n",
       " 'heal_tokens',\n",
       " 'init_weights',\n",
       " 'invert_attention_mask',\n",
       " 'ipu',\n",
       " 'is_gradient_checkpointing',\n",
       " 'is_parallelizable',\n",
       " 'load_adapter',\n",
       " 'load_state_dict',\n",
       " 'loss_function',\n",
       " 'main_input_name',\n",
       " 'model_tags',\n",
       " 'modules',\n",
       " 'mtia',\n",
       " 'name_or_path',\n",
       " 'named_buffers',\n",
       " 'named_children',\n",
       " 'named_modules',\n",
       " 'named_parameters',\n",
       " 'num_parameters',\n",
       " 'parameters',\n",
       " 'pooler',\n",
       " 'position_embedding_type',\n",
       " 'post_init',\n",
       " 'prepare_inputs_for_generation',\n",
       " 'prune_heads',\n",
       " 'push_to_hub',\n",
       " 'register_backward_hook',\n",
       " 'register_buffer',\n",
       " 'register_for_auto_class',\n",
       " 'register_forward_hook',\n",
       " 'register_forward_pre_hook',\n",
       " 'register_full_backward_hook',\n",
       " 'register_full_backward_pre_hook',\n",
       " 'register_load_state_dict_post_hook',\n",
       " 'register_load_state_dict_pre_hook',\n",
       " 'register_module',\n",
       " 'register_parameter',\n",
       " 'register_state_dict_post_hook',\n",
       " 'register_state_dict_pre_hook',\n",
       " 'requires_grad_',\n",
       " 'reset_memory_hooks_state',\n",
       " 'resize_position_embeddings',\n",
       " 'resize_token_embeddings',\n",
       " 'retrieve_modules_from_names',\n",
       " 'reverse_bettertransformer',\n",
       " 'save_pretrained',\n",
       " 'set_adapter',\n",
       " 'set_extra_state',\n",
       " 'set_input_embeddings',\n",
       " 'set_submodule',\n",
       " 'share_memory',\n",
       " 'state_dict',\n",
       " 'supports_gradient_checkpointing',\n",
       " 'tie_weights',\n",
       " 'to',\n",
       " 'to_bettertransformer',\n",
       " 'to_empty',\n",
       " 'train',\n",
       " 'training',\n",
       " 'type',\n",
       " 'warn_if_padding_and_no_attention_mask',\n",
       " 'warnings_issued',\n",
       " 'xpu',\n",
       " 'zero_grad']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T21:51:45.375560Z",
     "start_time": "2024-11-24T21:51:45.336645Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "cos_sim = lambda x, y: np.dot(x, y) / (np.linalg.norm(x) * np.linalg.norm(y))\n",
    "\n",
    "berlin_embedding = model.encode('Berlin')\n",
    "\n",
    "for chunk, new_embedding, trad_embeddings in zip(chunks, embeddings, embeddings_traditional_chunking):\n",
    "    print(f'similarity_new(\"Berlin\", \"{chunk}\"):', cos_sim(berlin_embedding, new_embedding))\n",
    "    print(f'similarity_trad(\"Berlin\", \"{chunk}\"):', cos_sim(berlin_embedding, trad_embeddings))"
   ],
   "id": "bd1f217bf1f06007",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'XLMRobertaModel' object has no attribute 'encode'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[40], line 5\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[0;32m      3\u001B[0m cos_sim \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mlambda\u001B[39;00m x, y: np\u001B[38;5;241m.\u001B[39mdot(x, y) \u001B[38;5;241m/\u001B[39m (np\u001B[38;5;241m.\u001B[39mlinalg\u001B[38;5;241m.\u001B[39mnorm(x) \u001B[38;5;241m*\u001B[39m np\u001B[38;5;241m.\u001B[39mlinalg\u001B[38;5;241m.\u001B[39mnorm(y))\n\u001B[1;32m----> 5\u001B[0m berlin_embedding \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencode\u001B[49m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mBerlin\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m chunk, new_embedding, trad_embeddings \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(chunks, embeddings, embeddings_traditional_chunking):\n\u001B[0;32m      8\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msimilarity_new(\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBerlin\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mchunk\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m):\u001B[39m\u001B[38;5;124m'\u001B[39m, cos_sim(berlin_embedding, new_embedding))\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1931\u001B[0m, in \u001B[0;36mModule.__getattr__\u001B[1;34m(self, name)\u001B[0m\n\u001B[0;32m   1929\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m modules:\n\u001B[0;32m   1930\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m modules[name]\n\u001B[1;32m-> 1931\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\n\u001B[0;32m   1932\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m object has no attribute \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1933\u001B[0m )\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'XLMRobertaModel' object has no attribute 'encode'"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T21:32:38.364500Z",
     "start_time": "2024-11-24T21:32:38.363942Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "b7ac5bb059d52e55",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "651d3733dfba452f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T20:40:39.544872Z",
     "start_time": "2024-11-26T20:40:39.470769Z"
    }
   },
   "cell_type": "code",
   "source": "from datetime import datetime, timedelta",
   "id": "e5d1fdf66fa4d30a",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T20:42:48.094533Z",
     "start_time": "2024-11-26T20:42:48.075080Z"
    }
   },
   "cell_type": "code",
   "source": "datetime(2024, 10, 5, 17, 4) + timedelta(minutes=295)",
   "id": "e727d8d4e514fdb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2024, 10, 5, 21, 59)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T20:41:13.826745Z",
     "start_time": "2024-11-26T20:41:13.821460Z"
    }
   },
   "cell_type": "code",
   "source": "(60 * 6 + 34) * 0.75",
   "id": "c42d71f68b9d3f19",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "295.5"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T23:54:30.976820Z",
     "start_time": "2024-11-26T23:54:30.794263Z"
    }
   },
   "cell_type": "code",
   "source": "import psycopg2",
   "id": "a92db96e67e69e0f",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T00:12:49.951160Z",
     "start_time": "2024-11-27T00:12:49.938491Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def connect_db():\n",
    "    return psycopg2.connect( # use the credentials of your postgresql database \n",
    "        host = '127.0.0.1',\n",
    "        database = 'jiraiya',\n",
    "        user = 'jiraiya',\n",
    "        password = '*v^TVZk7u6h3m2',\n",
    "        port = '9012'\n",
    "    )"
   ],
   "id": "873a63ce2b5b7f3",
   "outputs": [],
   "execution_count": 91
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T00:12:50.182517Z",
     "start_time": "2024-11-27T00:12:50.157688Z"
    }
   },
   "cell_type": "code",
   "source": "conn = connect_db()",
   "id": "4381f515080fa037",
   "outputs": [],
   "execution_count": 92
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T00:12:51.531976Z",
     "start_time": "2024-11-27T00:12:51.525348Z"
    }
   },
   "cell_type": "code",
   "source": "conn",
   "id": "93a753d78d67d983",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<connection object at 0x0000023F879B4E10; dsn: 'user=jiraiya password=xxx dbname=jiraiya host=127.0.0.1 port=9012', closed: 0>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 93
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T00:13:28.970975Z",
     "start_time": "2024-11-27T00:13:28.867429Z"
    }
   },
   "cell_type": "code",
   "source": [
    "conn = connect_db()\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS documents (\n",
    "            id SERIAL PRIMARY KEY,\n",
    "            title TEXT,\n",
    "            content TEXT,\n",
    "            embedding VECTOR(768)\n",
    "        );\n",
    "    \"\"\")\n",
    "conn.commit()\n",
    "cur.close()\n",
    "conn.close()"
   ],
   "id": "dd9b527d1e8c0d74",
   "outputs": [],
   "execution_count": 94
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T00:13:46.358675Z",
     "start_time": "2024-11-27T00:13:46.348626Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dummy_data = [\n",
    "    {\"title\": \"Seoul Tower\", \"content\": \"Seoul Tower is a communication and observation tower located on Namsan Mountain in central Seoul, South Korea.\"},\n",
    "    {\"title\": \"Gwanghwamun Gate\", \"content\": \"Gwanghwamun is the main and largest gate of Gyeongbokgung Palace, in Jongno-gu, Seoul, South Korea.\"},\n",
    "    {\"title\": \"Bukchon Hanok Village\", \"content\": \"Bukchon Hanok Village is a Korean traditional village in Seoul with a long history.\"},\n",
    "    {\"title\": \"Myeong-dong Shopping Street\", \"content\": \"Myeong-dong is one of the primary shopping districts in Seoul, South Korea.\"},\n",
    "    {\"title\": \"Dongdaemun Design Plaza\", \"content\": \"The Dongdaemun Design Plaza is a major urban development landmark in Seoul, South Korea.\"}\n",
    "]"
   ],
   "id": "4a0a18b41e794feb",
   "outputs": [],
   "execution_count": 95
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "99a5798146bf449c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T00:27:28.537611Z",
     "start_time": "2024-11-27T00:27:28.474340Z"
    }
   },
   "cell_type": "code",
   "source": [
    "conn = connect_db()\n",
    "cur = conn.cursor()\n",
    "\n",
    "# use the port at which your ollama service is running.\n",
    "a = cur.execute(\"\"\"\n",
    "   create table quotes\n",
    "( id int not null primary key generated by default as identity\n",
    ", quote text\n",
    ", person text\n",
    ", embedding vector(4096) -- the vector data type is from the pgvector extension\n",
    ");\n",
    "\"\"\")\n",
    "conn.commit()\n",
    "cur.close()\n",
    "conn.close()"
   ],
   "id": "81be5a88586d3a8d",
   "outputs": [],
   "execution_count": 104
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T00:27:38.174231Z",
     "start_time": "2024-11-27T00:27:38.111312Z"
    }
   },
   "cell_type": "code",
   "source": [
    "conn = connect_db()\n",
    "cur = conn.cursor()\n",
    "\n",
    "# use the port at which your ollama service is running.\n",
    "a = cur.execute(\"\"\"\n",
    "insert into quotes (quote, person) values\n",
    "  ('What one programmer can do in one month, two programmers can do in two months.', 'Frederick P. Brooks')\n",
    ", ('The only way to learn a new programming language is by writing programs in it.', 'Dennis Ritchie')\n",
    ", ('Talk is cheap. Show me the code.', 'Linus Torvalds')\n",
    ";\n",
    "\"\"\")\n",
    "conn.commit()\n",
    "cur.close()\n",
    "conn.close()"
   ],
   "id": "4c5594439873c81",
   "outputs": [],
   "execution_count": 105
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T00:41:25.766821Z",
     "start_time": "2024-11-27T00:41:25.464311Z"
    }
   },
   "cell_type": "code",
   "source": [
    "conn = connect_db()\n",
    "cur = conn.cursor()\n",
    "\n",
    "# use the port at which your ollama service is running.\n",
    "cur.execute(\"\"\"\n",
    "update quotes set embedding = ai.ollama_embed('llama3'::text, format('%s - %s', person, quote)::text);\n",
    "\"\"\")\n",
    "\n",
    "conn.commit()\n",
    "cur.close()\n",
    "conn.close()"
   ],
   "id": "a457514a79b608b3",
   "outputs": [
    {
     "ename": "ExternalRoutineException",
     "evalue": "httpx.ConnectError: [Errno 111] Connection refused\nCONTEXT:  Traceback (most recent call last):\n  PL/Python function \"ollama_embed\", line 21, in <module>\n    resp = client.embeddings(model, input_text, options=embedding_options_1, keep_alive=keep_alive)\n  PL/Python function \"ollama_embed\", line 200, in embeddings\n  PL/Python function \"ollama_embed\", line 68, in _request\n  PL/Python function \"ollama_embed\", line 836, in request\n  PL/Python function \"ollama_embed\", line 925, in send\n  PL/Python function \"ollama_embed\", line 953, in _send_handling_auth\n  PL/Python function \"ollama_embed\", line 990, in _send_handling_redirects\n  PL/Python function \"ollama_embed\", line 1026, in _send_single_request\n  PL/Python function \"ollama_embed\", line 234, in handle_request\n  PL/Python function \"ollama_embed\", line 152, in __exit__\n  PL/Python function \"ollama_embed\", line 88, in map_httpcore_exceptions\nPL/Python function \"ollama_embed\"\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mExternalRoutineException\u001B[0m                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[117], line 5\u001B[0m\n\u001B[0;32m      2\u001B[0m cur \u001B[38;5;241m=\u001B[39m conn\u001B[38;5;241m.\u001B[39mcursor()\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m# use the port at which your ollama service is running.\u001B[39;00m\n\u001B[1;32m----> 5\u001B[0m \u001B[43mcur\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\"\"\u001B[39;49m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;124;43mupdate quotes set embedding = ai.ollama_embed(\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mllama3\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m::text, format(\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;132;43;01m%s\u001B[39;49;00m\u001B[38;5;124;43m - \u001B[39;49m\u001B[38;5;132;43;01m%s\u001B[39;49;00m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m, person, quote)::text);\u001B[39;49m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;124;43m\"\"\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      9\u001B[0m conn\u001B[38;5;241m.\u001B[39mcommit()\n\u001B[0;32m     10\u001B[0m cur\u001B[38;5;241m.\u001B[39mclose()\n",
      "\u001B[1;31mExternalRoutineException\u001B[0m: httpx.ConnectError: [Errno 111] Connection refused\nCONTEXT:  Traceback (most recent call last):\n  PL/Python function \"ollama_embed\", line 21, in <module>\n    resp = client.embeddings(model, input_text, options=embedding_options_1, keep_alive=keep_alive)\n  PL/Python function \"ollama_embed\", line 200, in embeddings\n  PL/Python function \"ollama_embed\", line 68, in _request\n  PL/Python function \"ollama_embed\", line 836, in request\n  PL/Python function \"ollama_embed\", line 925, in send\n  PL/Python function \"ollama_embed\", line 953, in _send_handling_auth\n  PL/Python function \"ollama_embed\", line 990, in _send_handling_redirects\n  PL/Python function \"ollama_embed\", line 1026, in _send_single_request\n  PL/Python function \"ollama_embed\", line 234, in handle_request\n  PL/Python function \"ollama_embed\", line 152, in __exit__\n  PL/Python function \"ollama_embed\", line 88, in map_httpcore_exceptions\nPL/Python function \"ollama_embed\"\n"
     ]
    }
   ],
   "execution_count": 117
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d29c530c83221dee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T00:35:57.097309Z",
     "start_time": "2024-11-27T00:35:57.065890Z"
    }
   },
   "cell_type": "code",
   "source": [
    "conn = connect_db()\n",
    "cur = conn.cursor()\n",
    "\n",
    "# use the port at which your ollama service is running.\n",
    "a = cur.execute(\"\"\"\n",
    "SELECT proname, proargtypes\n",
    "FROM pg_proc\n",
    "WHERE proname = 'ollama_embed';\n",
    "\"\"\")\n",
    "cur.fetchall()\n"
   ],
   "id": "1959a6a57adfc9b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ollama_embed', '25 25 25 701 3802')]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 114
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T00:25:04.517488Z",
     "start_time": "2024-11-27T00:25:04.501779Z"
    }
   },
   "cell_type": "code",
   "source": "a",
   "id": "f876f9c78199f02e",
   "outputs": [],
   "execution_count": 100
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T00:41:58.326979Z",
     "start_time": "2024-11-27T00:41:58.253993Z"
    }
   },
   "cell_type": "code",
   "source": [
    "conn = connect_db()\n",
    "cur = conn.cursor()\n",
    "\n",
    "# use the port at which your ollama service is running.\n",
    "for doc in dummy_data:\n",
    "    cur.execute(\"\"\"\n",
    "        INSERT INTO documents (title, content, embedding)\n",
    "        VALUES (\n",
    "            %(title)s,\n",
    "            %(content)s,\n",
    "            ai.ollama_embed('nomic-embed-text', concat(%(title)s, ' - ', %(content)s), _host=>'http://ollama:11434')\n",
    "        )\n",
    "    \"\"\", doc)\n",
    "\n",
    "conn.commit()\n",
    "cur.close()\n",
    "conn.close()"
   ],
   "id": "fadcbacc93df6ef5",
   "outputs": [
    {
     "ename": "UndefinedFunction",
     "evalue": "function ai.ollama_embed(unknown, text, _host => unknown) does not exist\nLINE 6:             ai.ollama_embed('nomic-embed-text', concat('Seou...\n                    ^\nHINT:  No function matches the given name and argument types. You might need to add explicit type casts.\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mUndefinedFunction\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[118], line 6\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m# use the port at which your ollama service is running.\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m doc \u001B[38;5;129;01min\u001B[39;00m dummy_data:\n\u001B[1;32m----> 6\u001B[0m     \u001B[43mcur\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\"\"\u001B[39;49m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;124;43m        INSERT INTO documents (title, content, embedding)\u001B[39;49m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;124;43m        VALUES (\u001B[39;49m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;124;43m            \u001B[39;49m\u001B[38;5;132;43;01m%(title)s\u001B[39;49;00m\u001B[38;5;124;43m,\u001B[39;49m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;124;43m            \u001B[39;49m\u001B[38;5;132;43;01m%(content)s\u001B[39;49;00m\u001B[38;5;124;43m,\u001B[39;49m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;124;43m            ai.ollama_embed(\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mnomic-embed-text\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m, concat(\u001B[39;49m\u001B[38;5;132;43;01m%(title)s\u001B[39;49;00m\u001B[38;5;124;43m, \u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m - \u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m, \u001B[39;49m\u001B[38;5;132;43;01m%(content)s\u001B[39;49;00m\u001B[38;5;124;43m), _host=>\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mhttp://ollama:11434\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m)\u001B[39;49m\n\u001B[0;32m     12\u001B[0m \u001B[38;5;124;43m        )\u001B[39;49m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;124;43m    \u001B[39;49m\u001B[38;5;124;43m\"\"\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdoc\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     15\u001B[0m conn\u001B[38;5;241m.\u001B[39mcommit()\n\u001B[0;32m     16\u001B[0m cur\u001B[38;5;241m.\u001B[39mclose()\n",
      "\u001B[1;31mUndefinedFunction\u001B[0m: function ai.ollama_embed(unknown, text, _host => unknown) does not exist\nLINE 6:             ai.ollama_embed('nomic-embed-text', concat('Seou...\n                    ^\nHINT:  No function matches the given name and argument types. You might need to add explicit type casts.\n"
     ]
    }
   ],
   "execution_count": 118
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T01:26:24.289754Z",
     "start_time": "2024-11-27T01:26:19.637778Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"example_collection\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"./chroma_langchain_db\",  # Where to save data locally, remove if not necessary\n",
    ")"
   ],
   "id": "3bb4b1d816570cb1",
   "outputs": [],
   "execution_count": 119
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import chromadb\n",
    "\n",
    "persistent_client = chromadb.PersistentClient()\n",
    "collection = persistent_client.get_or_create_collection(\"collection_name\")\n",
    "collection.add(ids=[\"1\", \"2\", \"3\"], documents=[\"a\", \"b\", \"c\"])\n",
    "\n",
    "vector_store_from_client = Chroma(\n",
    "    client=persistent_client,\n",
    "    collection_name=\"collection_name\",\n",
    "    embedding_function=embeddings,\n",
    ")\n",
    "\n"
   ],
   "id": "a6e494d75a43be87"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T01:27:36.559778Z",
     "start_time": "2024-11-27T01:27:36.535143Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import chromadb\n",
    "\n",
    "chroma_client = chromadb.Client()\n",
    "collection = chroma_client.get_or_create_collection(name=\"my_collection\")"
   ],
   "id": "572ab1b91da954fd",
   "outputs": [],
   "execution_count": 120
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T01:29:38.800042Z",
     "start_time": "2024-11-27T01:29:38.747577Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import chromadb\n",
    "chroma_client = chromadb.HttpClient(host='localhost', port=8027)\n"
   ],
   "id": "f96d7ef58bd2a925",
   "outputs": [],
   "execution_count": 122
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T01:32:24.051271Z",
     "start_time": "2024-11-27T01:32:24.036573Z"
    }
   },
   "cell_type": "code",
   "source": "chroma_client",
   "id": "1148907690213b0f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<chromadb.api.client.Client at 0x23f8a3c2f10>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 123
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "16b2d991f7619ea1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "906635defc40e697"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "dfe261faf647b058"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "cce528afd325f39f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
